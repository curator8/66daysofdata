# 66daysofdata
Personal accounts of my 66 day journey on learning about data science. 

# day 1 

So this is day 1 of 66 days of my data journey, at the moment, I am following this Github's page Data Analyst recommend learning path (https://lnkd.in/drJYYgi) to go over some the basic syntax and packages on python, you can view my code here https://lnkd.in/dgPnfSK. The course I am following was created by Maxwell Armi (https://lnkd.in/diVsFH8)

# day 2
yeah it's technically day 3, but I haven't fallen asleep yet so I figured I report what I learned throughout the day (for day 2). I also decided to include some stuff I am learning from my statistics tutoring position, applied statistical analysis, and algorithms and data structure class since they're relevant to my Data Science journey. 

At the moment I am learning about Multiple linear Regression, we just recently started the chapter on confounding between predictor variables and how it affects the overall analysis. In my tutoring session, I had to explain various probability rules like general addition rule versus addition rule or concepts like disjoint events versus independent events (to be honest they still confuse me :D). In my data structures and algorithms class, I've been working in a team setting to work on a tweet program, where we can add, edit, like, and print tweets on the console (so far it's been fun and challenging). 

In terms of python, I learned for loop syntax through Maxwell Armi's implementation of a selection sort algorithm using 2 for loops. To be honest, I definitely see the appeal of learning python as a first language, since it's very clear on what's what. ANYWAYS, that's all for today, thanks for reading!

# day 3
I was catching up on some assignments last night so I didn't get a chance to post on my day 3 progress. I'm still on Maxwell Armi's python course, the good news is I am about half way through. I think it helps that I have a programming background which allows me to skim over some topics.

I mainly reviewed a lot of statistics yesterday. I read some more on how we interpret cofounding and the coefficient of determination when applying multiple linear regression in context of the given question and data. That being said, my applied statistical analysis teacher recently assigned a project to us to apply some of the concepts we learned so far which should be fun :).

I also brushed up on some previous concept like binomial distribution (and function) to help a fellow student with some of the intuition behind it and how to solve different sorts problems associated with it. But, that's all for today, thanks for reading!

# day 4 
Good morning everyone, yesterday wasn't as productive as a I hoped, since I had to catch up on some discrete math and statistics HW. But since those two classes are relevant to the whole data journey, talking about them counts!

In discrete math, we're learning about proofs. I definitely see all the hype (not really) behind them. To do a proof requires a strict style of thinking, and in a computer scientist case, a strict style of thinking on the nature of countable items. I am little foggy on the concepts, but I have to pretty much prove a theorem, such as "all numbers are integers are positive" (or there is a number that is positive), by presenting hypotheses that eventually leads to the conclusion. So far, I learned there are different styles of arguments, but I need more time to practice them first. 

In Statistics, I continued refining my understanding on cofounding and interaction between predictor variables and determining whether by adding an extra predictor variable in the analysis affects the original X-Y relationship. I am guessing analyzing cofounding is a nice numerical measure on the effects on adding a variable, that being said, I have to be careful not to confuse it with correlation or the coefficient of determination.  

# day 5 

this is my edit using the git/github workflow! I will add some more comments later tonight.
SO yesterday wasn't entirely related to data science but rather to tools that can benefit my journey. I was able apply the whole git/Github workflow to a research project at ECU on personalized learning. The task I'm doing isn't fancy, I am basically helping a professor convert Rmarkdown to a static website using Jekyll. The eventual goal of the website is to help fellow CS student tailor they're learning by repeating randomly generated assessments. 

Another thing I focused on was taking the time at work to expose myself to the ideas behind machine learning and the math that goes into them. During this time, I started seeing machine learning as more of a math problem, rather than a coding problem, where we're trying to optimize a model to get better at guessing a wanted value. A lot like the idea behind limits, we plug and chug values within a parameter(s) to get closer to the true model adjusting for error along the way. Although I plan on fleshing these idea out much further, some links that helped me realize this: https://www.youtube.com/watch?v=MDL384gsAk0&t=510s , https://www.youtube.com/watch?v=uZeDTwWcnuY&t=544s, https://www.youtube.com/watch?v=VwVg9jCtqaU

# day 6

Yesterday was much more productive since I mainly focused on statistics, NumPy, and the overview of the field data science.

Lately statistics has been sorta confusing. Overall to get numerical measures like coefficient of determination (or even partial coefficient of determination) is an easy plug and chug process, the interpretation of those numbers and how they relate to the overall analysis is confusing. Fortunately stepping away from it has inched me forward to a more intuitive understanding.

One thing that has been going well is my progress with Maxwell Armi's python video (https://lnkd.in/dWjjUVz). I am reviewing array setups using NumPy and recently started working with the Jupyter Notebook.

Another cool thing I have been doing is listening to a good video by Barton Poulson (https://lnkd.in/dJs-5ss). His video is a lot like an intro to "insert field here" that goes over salary, jobs, fields (and there intersections), etc. More importantly he also goes over the math, tools, and workflow a data scientist will eventually go through. I feel like understanding these topics will help me define the steps I need to take to become a data scientist.

# day 7 

Yesterday was a bit of a busy day so I didn't have time to focus on python, or really anything else other than statistics.

Since I have a midterm due I mainly reviewed some of the stuff on SLR and how to get a confidence interval from each point estimate (B0, B1, and Y = B0 + B1x). I also met with my professor to go over hypothesis testing for MLR, to test whether adding a covariate is significant or not. Finally before and during work I went over some more fundamental concepts like normal distribution, standardized normal distribution, and central limit theorem which are really important to know when making inferences about a population.

# day 8-11

So this last week threw me for a loop. Between work and school, I was prepping for my statistics midterm (that was yesterday).

Since I wanted to do well on my midterm, I reviewed a lot of statistic concepts the last few days. Specifically, normal distribution, standardized normal distribution, z-score, t-distribution, F-distribution, hypothesis testing, p-value, simple linear regression, correlation, ANOVA table, MLR, and hypothesis testing for MLR.

At work I continued to listen to Barton Poulson overview of data science (https://lnkd.in/d_GTanb). He helped me realized a good data scientist tries to do three things; First, state goals. Second, keep a "story" in mind. And third, be clear and concise. Since this week is almost over (I still have another half of the test to finish), I'll be back on track with learning more about pandas in python.

# day 12-13

A little late,but I was finally able to finish the other half my statistics exam. Looking back, taking this exam really solidified a lot of important concepts. Although it took a bit to complete, the second half of the exam was mainly about applying what we learned by analyzing data using either excel or minitab. I really like this portion because we had to translate outputs into intuitive statements like "we're 90% confident that there will be 10 calls at 90 degrees F" or determine the usefulness of adding another variable in multiple linear regression.

But although I learned a lot, like anybody else, I am glad that's over. Looking forward to getting back on track with pandas and the overall data analytics track I set out to finish these next 2 months.

# day 14-15

I am starting to get back into the groove of things. We started a new programming assignment in my data structures and algorithm class that requires us to work with 2D arrays and text files, definitely looking forward to learning more about them. In discrete math we started learning about set theory, which showed up a lot when I went over probability in my previous statistics class. So far, I feel like discrete math has really built my foundation to learn harder math topics. 

In terms of data analysis, I actually started a new course by Santiago Basulto (https://www.youtube.com/watch?v=r-uOLxNrNk8). So far we set up a google colab and Github repository (https://github.com/curator8/66daysofdata), that uses Jupyter Notebook (and a variety of python packages) to describe the data. I am excited about this course because Santiago has fleshed out examples that run through the first steps of the data science workflow (data collection, cleaning, and wrangling).  
